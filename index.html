<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Nihal Gunukula</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=DM+Sans:wght@400;500;600;700&display=swap" rel="stylesheet">
</head>
<body>
    <main>
        <section id="home" class="hero">
            <div class="container">
                <h1>Nihal Gunukula</h1>
            </div>
        </section>

        <section id="about" class="section">
            <div class="container">
                <h2>About me</h2>
                <p class="last-updated">Last updated: December 2025</p>
                <div class="content">
                    <p>
                        I'm building <a href="https://phyvant.com" target="_blank">Phyvant</a>, a privacy-preserving ML platform for regulated industries. 
                        We do federated fine-tuning with differential privacy so enterprises can train on sensitive data without memorization risks. 
                        The idea is simple: companies like hospitals, law firms, and financial institutions have valuable data they can't send to OpenAI. 
                        We let them train models locally and aggregate the learning without exposing the underlying data.
                    </p>
                    <p>
                        First customer is <a href="https://www.cargill.com/" target="_blank">Cargill</a> (world's largest private company). Active conversations with healthcare systems, law firms, and financial services companies.
                    </p>
                    <p>
                        Previously ML Engineer at <a href="https://www.mercor.com/research/" target="_blank">Mercor</a>, working on RLHF systems for model quality. First-author paper at IROS 2025 on human-like crowd navigation using reinforcement learning, with <a href="https://www.cs.purdue.edu/homes/ab/" target="_blank">Professor Aniket Bera</a> at <a href="https://ideas.cs.purdue.edu/" target="_blank">IDEAS Lab</a>, Purdue.
                    </p>
                    <p>
                        CS junior at Purdue, graduating 2026 or 2027 depending on what happens with Phyvant.
                    </p>
                </div>
            </div>
        </section>

        <section id="interests" class="section">
            <div class="container">
                <h2>Interests</h2>
                <div class="content">
                    <p>
                        Privacy-preserving ML. Federated learning. Differential privacy. RLHF (PPO, DPO). Distributed systems that don't go down.
                    </p>
                    <p>
                        I like building infrastructure that works under constraints. There's something satisfying about making a system that's simultaneously private, accurate, and fast, when conventional wisdom says you can only pick two.
                    </p>
                    <p>
                        Long-term, I'm drawn to problems where ML meets high-stakes decisions: healthcare, defense, autonomous systems. Places where you can't afford to be wrong and "we'll fix it in the next release" isn't acceptable.
                    </p>
                    <p>
                        I also like thinking about the business side of enterprise software. Selling to large companies is a different game than consumer products. Longer cycles, more stakeholders, higher trust requirements. It's frustrating and fascinating.
                    </p>
                </div>
            </div>
        </section>

        <section id="non-professional" class="section">
            <div class="container">
                <h2>Non-professional interests</h2>
                <div class="content">
                    <ul class="interests-list">
                        <li>Chess (competitive play and puzzles)</li>
                        <li>Basketball (playing and watching)</li>
                        <li>Snowboarding (trying to get better without injuring myself)</li>
                        <li>Hiking (trying to do more of this)</li>
                        <li>Origami (started as a focus thing, now I just like it)</li>
                        <li>Anime and manga (Steins Gate, Vinland Saga, Monster)</li>
                        <li>Competitive programming when I have time</li>
                        <li>Meeting people building things that matter</li>
                    </ul>
                </div>
            </div>
        </section>

        <section id="fun-facts" class="section">
            <div class="container">
                <h2>Fun facts</h2>
                <div class="content">
                    <ul class="fun-facts-list">
                        <li>Won $45K+ in pitch competitions and hackathons</li>
                        <li><a href="https://www.cs.purdue.edu/news/articles/2024/2024_purdue_cs_awards.html" target="_blank">CS Freshman of the Year</a> at Purdue</li>
                        <li>Currently trying to get better at snowboarding without injuring myself</li>
                    </ul>
                </div>
            </div>
        </section>

        <section id="publications" class="section">
            <div class="container">
                <h2>Research</h2>
                <div class="content">
                    <div class="publication-item">
                        <p>
                            <strong>Nihal Gunukula</strong>, Aniket Bera (2025). 
                            <a href="https://ras.papercept.net/conferences/conferences/IROS25/program/IROS25_ContentListWeb_2.html" target="_blank" class="publication-link">PathCluster: Pedestrian Group-Adaptive Social Navigation in Dense Crowds</a>. 
                            <em>IROS 2025</em> [Accepted]
                        </p>
                    </div>
                    <div class="publication-item">
                        <p>
                            <strong>Nihal Gunukula</strong>, Kshitij Tiwari, Aniket Bera (2023). 
                            <a href="https://arxiv.org/pdf/2312.03651" target="_blank" class="publication-link">MIRACLE: Inverse Reinforcement and Curriculum Learning Model for Human-inspired Mobile Robot Navigation</a>. 
                            <em>arXiv 2023</em>
                        </p>
                    </div>
                </div>
            </div>
        </section>

        <section id="contact" class="section">
            <div class="container">
                <h2>Contact</h2>
                <div class="content">
                    <p>I read everything.</p>
                    <ul class="contact-list">
                        <li>Email: <a href="mailto:nihalgunukula@gmail.com">nihalgunukula@gmail.com</a></li>
                        <li>LinkedIn: <a href="https://linkedin.com/in/nihalgunu" target="_blank">linkedin.com/in/nihalgunu</a></li>
                    </ul>
                    <p>If you're working on something interesting, I'd like to hear about it.</p>
                </div>
            </div>
        </section>
    </main>

    <footer>
        <div class="container">
            <p>&copy; 2025 Nihal Gunukula</p>
        </div>
    </footer>

    <script src="script.js"></script>
</body>
</html>
